{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn import metrics \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.sklearn import EnsembleClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['clf', 'test']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please build a classifier to predict the probability of a user purchasing from Staples.com by looking at the first 8 pages viewed by the user in the session.  Use the classifier to predict the labels for the data in the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load Dara \n",
    "train = pd.read_csv('SparX/train.csv', header = None)\n",
    "test = pd.read_csv('SparX/test.csv', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_names_train = ['activity_1','time_1','activity_2','time_2','activity_3','time_3','activity_4','time_4','activity_5','time_5',\n",
    "                 'activity_6','time_6','activity_7','time_7','activity_8','time_8','target']\n",
    "\n",
    "col_names_test = ['activity_1','time_1','activity_2','time_2','activity_3','time_3','activity_4','time_4','activity_5','time_5',\n",
    "                 'activity_6','time_6','activity_7','time_7','activity_8','time_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_1</th>\n",
       "      <th>time_1</th>\n",
       "      <th>activity_2</th>\n",
       "      <th>time_2</th>\n",
       "      <th>activity_3</th>\n",
       "      <th>time_3</th>\n",
       "      <th>activity_4</th>\n",
       "      <th>time_4</th>\n",
       "      <th>activity_5</th>\n",
       "      <th>time_5</th>\n",
       "      <th>activity_6</th>\n",
       "      <th>time_6</th>\n",
       "      <th>activity_7</th>\n",
       "      <th>time_7</th>\n",
       "      <th>activity_8</th>\n",
       "      <th>time_8</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  53</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 442</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 528</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 541</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 545</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 668</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 686</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td>  17</td>\n",
       "      <td>      CLASS</td>\n",
       "      <td>  53</td>\n",
       "      <td>          CLASS</td>\n",
       "      <td>  96</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 180</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 631</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 641</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 647</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 891</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 891</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 899</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 899</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 937</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 949</td>\n",
       "      <td>           CART</td>\n",
       "      <td> 973</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td>   7</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 726</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td> 731</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td> 740</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td> 744</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td> 753</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td> 768</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td>  35</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>  35</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td>  41</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 139</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 139</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 247</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td> 263</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_1  time_1      activity_2  time_2  activity_3  time_3  \\\n",
       "0  OTHER_PAGE       0             SKU      53  OTHER_PAGE     442   \n",
       "1  OTHER_PAGE       0      OTHER_PAGE      17       CLASS      53   \n",
       "2  OTHER_PAGE       0      OTHER_PAGE     891  OTHER_PAGE     891   \n",
       "3  OTHER_PAGE       0  SEARCH_RESULTS       7  OTHER_PAGE     726   \n",
       "4  OTHER_PAGE       0      OTHER_PAGE      35  OTHER_PAGE      35   \n",
       "\n",
       "       activity_4  time_4      activity_5  time_5      activity_6  time_6  \\\n",
       "0             SKU     528             SKU     541             SKU     545   \n",
       "1           CLASS      96            CART     180            CART     631   \n",
       "2             SKU     899             SKU     899            CART     937   \n",
       "3  SEARCH_RESULTS     731  SEARCH_RESULTS     740  SEARCH_RESULTS     744   \n",
       "4      OTHER_PAGE      41      OTHER_PAGE     139      OTHER_PAGE     139   \n",
       "\n",
       "       activity_7  time_7      activity_8  time_8  target  \n",
       "0      OTHER_PAGE     668      OTHER_PAGE     686       0  \n",
       "1            CART     641      OTHER_PAGE     647       1  \n",
       "2            CART     949            CART     973       0  \n",
       "3  SEARCH_RESULTS     753  SEARCH_RESULTS     768       0  \n",
       "4             SKU     247      OTHER_PAGE     263       0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns = col_names_train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'activity_1', u'time_1', u'activity_2', u'time_2', u'activity_3', u'time_3', u'activity_4', u'time_4', u'activity_5', u'time_5', u'activity_6', u'time_6', u'activity_7', u'time_7', u'activity_8', u'time_8', u'target'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_1</th>\n",
       "      <th>time_1</th>\n",
       "      <th>activity_2</th>\n",
       "      <th>time_2</th>\n",
       "      <th>activity_3</th>\n",
       "      <th>time_3</th>\n",
       "      <th>activity_4</th>\n",
       "      <th>time_4</th>\n",
       "      <th>activity_5</th>\n",
       "      <th>time_5</th>\n",
       "      <th>activity_6</th>\n",
       "      <th>time_6</th>\n",
       "      <th>activity_7</th>\n",
       "      <th>time_7</th>\n",
       "      <th>activity_8</th>\n",
       "      <th>time_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>        SKU</td>\n",
       "      <td> 0</td>\n",
       "      <td>        SKU</td>\n",
       "      <td> 373</td>\n",
       "      <td>        SKU</td>\n",
       "      <td> 817</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 1546</td>\n",
       "      <td>        SKU</td>\n",
       "      <td> 1696</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 1706</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 1717</td>\n",
       "      <td>            SKU</td>\n",
       "      <td> 1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>  43</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>  68</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td>  111</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>  111</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  206</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  206</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   0</td>\n",
       "      <td>        SKU</td>\n",
       "      <td>  26</td>\n",
       "      <td>     OTHER_PAGE</td>\n",
       "      <td>   47</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   48</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td>   89</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td>   95</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td>  106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>        SKU</td>\n",
       "      <td> 0</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   7</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   7</td>\n",
       "      <td>           CART</td>\n",
       "      <td>   16</td>\n",
       "      <td>       CART</td>\n",
       "      <td>   74</td>\n",
       "      <td>           CART</td>\n",
       "      <td>  174</td>\n",
       "      <td>           CART</td>\n",
       "      <td>  241</td>\n",
       "      <td>           CART</td>\n",
       "      <td>  458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td> 0</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   0</td>\n",
       "      <td> OTHER_PAGE</td>\n",
       "      <td>   7</td>\n",
       "      <td> SEARCH_RESULTS</td>\n",
       "      <td>   16</td>\n",
       "      <td>        SKU</td>\n",
       "      <td>   34</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  314</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  335</td>\n",
       "      <td>            SKU</td>\n",
       "      <td>  387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   activity_1  time_1  activity_2  time_2  activity_3  time_3      activity_4  \\\n",
       "0         SKU       0         SKU     373         SKU     817             SKU   \n",
       "1  OTHER_PAGE       0  OTHER_PAGE      43  OTHER_PAGE      68      OTHER_PAGE   \n",
       "2  OTHER_PAGE       0  OTHER_PAGE       0         SKU      26      OTHER_PAGE   \n",
       "3         SKU       0  OTHER_PAGE       7  OTHER_PAGE       7            CART   \n",
       "4  OTHER_PAGE       0  OTHER_PAGE       0  OTHER_PAGE       7  SEARCH_RESULTS   \n",
       "\n",
       "   time_4  activity_5  time_5      activity_6  time_6      activity_7  time_7  \\\n",
       "0    1546         SKU    1696             SKU    1706             SKU    1717   \n",
       "1     111  OTHER_PAGE     111             SKU     206             SKU     206   \n",
       "2      47  OTHER_PAGE      48  SEARCH_RESULTS      89  SEARCH_RESULTS      95   \n",
       "3      16        CART      74            CART     174            CART     241   \n",
       "4      16         SKU      34             SKU     314             SKU     335   \n",
       "\n",
       "       activity_8  time_8  \n",
       "0             SKU    1727  \n",
       "1             SKU     292  \n",
       "2  SEARCH_RESULTS     106  \n",
       "3            CART     458  \n",
       "4             SKU     387  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns = col_names_test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'activity_1', u'time_1', u'activity_2', u'time_2', u'activity_3', u'time_3', u'activity_4', u'time_4', u'activity_5', u'time_5', u'activity_6', u'time_6', u'activity_7', u'time_7', u'activity_8', u'time_8'], dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['target']\n",
    "del train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat_features_corpus(data):\n",
    "    '''\n",
    "    Create a corpus form the different activities per transaction\n",
    "    '''\n",
    "    activity_corpus = []\n",
    "\n",
    "    countvec = data[['activity_1','activity_2','activity_3','activity_4','activity_5','activity_6',\\\n",
    "                      'activity_7','activity_8']]\n",
    "\n",
    "    for i in range(len(countvec)):\n",
    "        activity_corpus.extend([(' ').join(countvec.ix[i,:])])\n",
    "                  \n",
    "    return activity_corpus\n",
    "\n",
    "def count_vectorizer(train_, test_, **mode):\n",
    "    '''\n",
    "    Create a count vectorized version og the inpute data for all the activities\n",
    "    in the original data\n",
    "    '''\n",
    "    count_vect = CountVectorizer()\n",
    "    \n",
    "    for name, value in mode.items():\n",
    "        if value is 'train':\n",
    "            train_data = count_vect.fit_transform(train_)\n",
    "            return pd.DataFrame(train_data.A, columns=count_vect.get_feature_names())\n",
    "        if value is 'test':\n",
    "            train_data = count_vect.fit_transform(train_)\n",
    "            test_data = count_vect.transform(test_)\n",
    "            return pd.DataFrame(test_data.A, columns=count_vect.get_feature_names())\n",
    "        \n",
    "def activity_time_delta_features(data):\n",
    "    '''\n",
    "    (dataframe) -> (dataframe)\n",
    "    Builds out a new set of features that shows the time delta between on activity \n",
    "    and the one before it\n",
    "    '''\n",
    "    time_features = data[['time_1','time_2','time_3','time_4','time_5','time_6','time_7','time_8']]\n",
    "\n",
    "    delta_87 = time_features['time_8'] - time_features['time_7']\n",
    "    delta_76 = time_features['time_7'] - time_features['time_6']\n",
    "    delta_65 = time_features['time_6'] - time_features['time_5']\n",
    "    delta_54 = time_features['time_5'] - time_features['time_4']\n",
    "    delta_43 = time_features['time_4'] - time_features['time_3']\n",
    "    delta_32 = time_features['time_3'] - time_features['time_2']\n",
    "    delta_21 = time_features['time_2'] \n",
    "    total_time = time_features['time_8']\n",
    "        \n",
    "    cols_data = [delta_87,delta_76,delta_65,delta_54,delta_43,delta_32,delta_21,total_time]\n",
    "    cols = ['delta_87','delta_76,','delta_65','delta_54','delta_43','delta_32','delta_21','total_time']\n",
    "\n",
    "    time_delta_df = pd.DataFrame()\n",
    "    for col_name, data in zip(cols, cols_data) :\n",
    "        time_delta_df[col_name] = data\n",
    "        \n",
    "    return time_delta_df\n",
    "\n",
    "def feature_engineering(train, test, **mode):\n",
    "    '''\n",
    "    (dataframe) -> (dataframe)\n",
    "    Feature Engineering Pipeline \n",
    "    This function applies the same feature engineering actions to both the training data and the prediction data \n",
    "    '''    \n",
    "    corpus_df_train = cat_features_corpus(train)\n",
    "    corpus_df_test = cat_features_corpus(test)\n",
    "    \n",
    "    time_train = activity_time_delta_features(train)\n",
    "    time_test = activity_time_delta_features(test)\n",
    "      \n",
    "    for name, value in mode.items():\n",
    "        if value is 'train':\n",
    "            train_vec_data = count_vectorizer(corpus_df_train, corpus_df_test, mode = 'train')\n",
    "            return train_vec_data.merge(time_train, left_index=True, right_index=True, how='left')\n",
    "        if value is 'test':\n",
    "            test_vec_data = count_vectorizer(corpus_df_train, corpus_df_test, mode = 'test')\n",
    "            return test_vec_data.merge(time_test, left_index=True, right_index=True, how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## run test and train data through feature engineering pipeline \n",
    "train_data = feature_engineering(train, test, mode = 'train')\n",
    "test_data = feature_engineering(train, test, mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>cart</th>\n",
       "      <th>class</th>\n",
       "      <th>department</th>\n",
       "      <th>home</th>\n",
       "      <th>other_page</th>\n",
       "      <th>search_results</th>\n",
       "      <th>sku</th>\n",
       "      <th>skuset</th>\n",
       "      <th>delta_87</th>\n",
       "      <th>delta_76,</th>\n",
       "      <th>delta_65</th>\n",
       "      <th>delta_54</th>\n",
       "      <th>delta_43</th>\n",
       "      <th>delta_32</th>\n",
       "      <th>delta_21</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td> 18</td>\n",
       "      <td> 123</td>\n",
       "      <td>   4</td>\n",
       "      <td> 13</td>\n",
       "      <td> 86</td>\n",
       "      <td> 389</td>\n",
       "      <td>  53</td>\n",
       "      <td> 686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td>  6</td>\n",
       "      <td>  10</td>\n",
       "      <td> 451</td>\n",
       "      <td> 84</td>\n",
       "      <td> 43</td>\n",
       "      <td>  36</td>\n",
       "      <td>  17</td>\n",
       "      <td> 647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 24</td>\n",
       "      <td>  12</td>\n",
       "      <td>  38</td>\n",
       "      <td>  0</td>\n",
       "      <td>  8</td>\n",
       "      <td>   0</td>\n",
       "      <td> 891</td>\n",
       "      <td> 973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 6</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 15</td>\n",
       "      <td>   9</td>\n",
       "      <td>   4</td>\n",
       "      <td>  9</td>\n",
       "      <td>  5</td>\n",
       "      <td> 719</td>\n",
       "      <td>   7</td>\n",
       "      <td> 768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 7</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 16</td>\n",
       "      <td> 108</td>\n",
       "      <td>   0</td>\n",
       "      <td> 98</td>\n",
       "      <td>  6</td>\n",
       "      <td>   0</td>\n",
       "      <td>  35</td>\n",
       "      <td> 263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account  cart  class  department  home  other_page  search_results  sku  \\\n",
       "0        0     0      0           0     0           4               0    4   \n",
       "1        0     3      2           0     0           3               0    0   \n",
       "2        0     3      0           0     0           3               0    2   \n",
       "3        0     0      0           0     0           2               6    0   \n",
       "4        0     0      0           0     0           7               0    1   \n",
       "\n",
       "   skuset  delta_87  delta_76,  delta_65  delta_54  delta_43  delta_32  \\\n",
       "0       0        18        123         4        13        86       389   \n",
       "1       0         6         10       451        84        43        36   \n",
       "2       0        24         12        38         0         8         0   \n",
       "3       0        15          9         4         9         5       719   \n",
       "4       0        16        108         0        98         6         0   \n",
       "\n",
       "   delta_21  total_time  \n",
       "0        53         686  \n",
       "1        17         647  \n",
       "2       891         973  \n",
       "3         7         768  \n",
       "4        35         263  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>cart</th>\n",
       "      <th>class</th>\n",
       "      <th>department</th>\n",
       "      <th>home</th>\n",
       "      <th>other_page</th>\n",
       "      <th>search_results</th>\n",
       "      <th>sku</th>\n",
       "      <th>skuset</th>\n",
       "      <th>delta_87</th>\n",
       "      <th>delta_76,</th>\n",
       "      <th>delta_65</th>\n",
       "      <th>delta_54</th>\n",
       "      <th>delta_43</th>\n",
       "      <th>delta_32</th>\n",
       "      <th>delta_21</th>\n",
       "      <th>total_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 8</td>\n",
       "      <td> 0</td>\n",
       "      <td>  10</td>\n",
       "      <td> 11</td>\n",
       "      <td>  10</td>\n",
       "      <td> 150</td>\n",
       "      <td> 729</td>\n",
       "      <td> 444</td>\n",
       "      <td> 373</td>\n",
       "      <td> 1727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 0</td>\n",
       "      <td>  86</td>\n",
       "      <td>  0</td>\n",
       "      <td>  95</td>\n",
       "      <td>   0</td>\n",
       "      <td>  43</td>\n",
       "      <td>  25</td>\n",
       "      <td>  43</td>\n",
       "      <td>  292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 4</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td>  11</td>\n",
       "      <td>  6</td>\n",
       "      <td>  41</td>\n",
       "      <td>   1</td>\n",
       "      <td>  21</td>\n",
       "      <td>  26</td>\n",
       "      <td>   0</td>\n",
       "      <td>  106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0</td>\n",
       "      <td> 5</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 217</td>\n",
       "      <td> 67</td>\n",
       "      <td> 100</td>\n",
       "      <td>  58</td>\n",
       "      <td>   9</td>\n",
       "      <td>   0</td>\n",
       "      <td>   7</td>\n",
       "      <td>  458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3</td>\n",
       "      <td> 1</td>\n",
       "      <td> 4</td>\n",
       "      <td> 0</td>\n",
       "      <td>  52</td>\n",
       "      <td> 21</td>\n",
       "      <td> 280</td>\n",
       "      <td>  18</td>\n",
       "      <td>   9</td>\n",
       "      <td>   7</td>\n",
       "      <td>   0</td>\n",
       "      <td>  387</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account  cart  class  department  home  other_page  search_results  sku  \\\n",
       "0        0     0      0           0     0           0               0    8   \n",
       "1        0     0      0           0     0           5               0    3   \n",
       "2        0     0      0           0     0           4               3    1   \n",
       "3        0     5      0           0     0           2               0    1   \n",
       "4        0     0      0           0     0           3               1    4   \n",
       "\n",
       "   skuset  delta_87  delta_76,  delta_65  delta_54  delta_43  delta_32  \\\n",
       "0       0        10         11        10       150       729       444   \n",
       "1       0        86          0        95         0        43        25   \n",
       "2       0        11          6        41         1        21        26   \n",
       "3       0       217         67       100        58         9         0   \n",
       "4       0        52         21       280        18         9         7   \n",
       "\n",
       "   delta_21  total_time  \n",
       "0       373        1727  \n",
       "1        43         292  \n",
       "2         0         106  \n",
       "3         7         458  \n",
       "4         0         387  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122907\n",
      "30967\n"
     ]
    }
   ],
   "source": [
    "print len(train_data)\n",
    "print len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "data_train, data_test, target_train, target_test = train_test_split(train_data, np.array(target), test_size=0.25, random_state=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be building models with several algorithmns to get a feel for what we may expect. \n",
    "\n",
    "- Random Forest \n",
    "- Ada Boost \n",
    "- Logistic REgression \n",
    "- KNN\n",
    "- Gradient Boosting \n",
    "- Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## build and test different tree based models\n",
    "\n",
    "def build_model(data_train, target_train, data_test, target_test,  clf):\n",
    "    clf.fit(data_train,target_train) \n",
    "    print(clf)\n",
    "    expected = target_test \n",
    "    predicted = clf.predict(data_test) \n",
    "    predicted_probs = clf.predict_proba(data_test)\n",
    "    #summarize\n",
    "    print(metrics.classification_report(expected,predicted)) \n",
    "    print(metrics.confusion_matrix(expected,predicted))\n",
    "    print 'ROC-AUC  : %0.3f' %(metrics.roc_auc_score (expected,predicted))\n",
    "    print 'Accuracy : %0.3f' %(metrics.accuracy_score (expected,predicted))\n",
    "        \n",
    "    return predicted, predicted_probs, clf\n",
    "\n",
    "\n",
    "\n",
    "def model_ensemble(*predictions, **prediction_mode):\n",
    "    '''    \n",
    "    Perform Model Averaging or ensembling\n",
    "\n",
    "    (predictions instances for the different models, string) -> (array)\n",
    "    Possible options prediction_modes : ['binary', 'probs_binary', 'probs_multi_class'] \n",
    "    \n",
    "    binary : 0/1 binary predictions\n",
    "    probs : likelihood / probabilities\n",
    "    \n",
    "    *prediction takes the prediction results from either a given set of instances of a prediction or    \n",
    "    all the preictions for all the intances in the prediction set\n",
    "    **prediction_mode takes the prediction mode\n",
    "    \n",
    "    binary\n",
    "    ------\n",
    "    bin_one\n",
    "    >>> array([0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 1 0 0])\n",
    "    bin_two\n",
    "    >>> array([0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 0])\n",
    "    bin_three\n",
    "    >>> array([0 0 0 1 0 1 1 1 0 1 1 1 0 0 1 1 1 0 0 1 0 1 0 0 0 1 1 1 1 0])\n",
    "    bin_four\n",
    "    >>> array([1 0 0 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 1 0 1])\n",
    "    model_ensemble(bin_one, bin_two, bin_three, bin_four, mode = 'binary')\n",
    "    >>> array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "       0, 0, 1, 0, 1, 0, 0])\n",
    "    \n",
    "    probs_binary / probs_multi_class\n",
    "    --------------------------------\n",
    "    probs_one\n",
    "    >>>[[ 0.14130402  0.63774128]\n",
    "     [ 0.50817373  0.98390654]\n",
    "     [ 0.11188119  0.7557338 ]\n",
    "     [ 0.22295128  0.21470534]\n",
    "     [ 0.0471746   0.18134759]]\n",
    "    probs_two\n",
    "    >>> [[ 0.43791867  0.2953648 ]\n",
    "     [ 0.17505953  0.73938007]\n",
    "     [ 0.55570754  0.91328122]\n",
    "     [ 0.57098714  0.9477655 ]\n",
    "     [ 0.03664345  0.21077864]]\n",
    "    probs_three\n",
    "    >>> [[ 0.94495286  0.31086103]\n",
    "     [ 0.73768356  0.97090608]\n",
    "     [ 0.47792986  0.06297078]\n",
    "     [ 0.12999474  0.3582617 ]\n",
    "     [ 0.22364166  0.59997857]]\n",
    "    model_ensemble(probs_one, probs_two, probs_three, mode = 'probs')\n",
    "    >>> array([[ 0.94285177,  0.45720821],\n",
    "       [ 0.57108943,  0.3851022 ],\n",
    "       [ 0.52443183,  0.89947945],\n",
    "       [ 0.56761841,  0.13814018],\n",
    "       [ 0.58913088,  0.45394568]])\n",
    "     '''\n",
    "    \n",
    "    for name, value in prediction_mode.items():\n",
    "        if value is 'probs':\n",
    "            # model averaging - Soft Ensembling\n",
    "            model_avg = np.array(predictions)\n",
    "            return model_avg.mean(axis = 0)\n",
    "        \n",
    "        majority_vote = []\n",
    "        if value is 'binary':    \n",
    "            # perform model averaging or majority vote - Hard Ensembling\n",
    "            # advisable to have odd number of models to break ties \n",
    "            for i in xrange(len(predictions)):\n",
    "                majority_vote.append(np.argmax(np.bincount((np.vstack((predictions)))[:,i])))\n",
    "            return np.array(majority_vote)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84     22509\n",
      "          1       0.53      0.36      0.43      8218\n",
      "\n",
      "avg / total       0.72      0.74      0.73     30727\n",
      "\n",
      "[[19923  2586]\n",
      " [ 5269  2949]]\n",
      "ROC-AUC  : 0.622\n",
      "Accuracy : 0.744\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators = 100)  \n",
    "rf_predicted,rf_predicted_probs, clf_ = build_model(data_train, target_train, data_test, target_test,  rf_model)\n",
    "# clf_.predict_proba(data_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
      "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84     22509\n",
      "          1       0.54      0.36      0.43      8218\n",
      "\n",
      "avg / total       0.72      0.75      0.73     30727\n",
      "\n",
      "[[20031  2478]\n",
      " [ 5277  2941]]\n",
      "ROC-AUC  : 0.624\n",
      "Accuracy : 0.748\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost Classifier\n",
    "ada_model=AdaBoostClassifier() \n",
    "ada_predicted,ada_predicted_probs, clf_ = build_model(data_train, target_train, data_test, target_test,  ada_model)\n",
    "# clf_.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            random_state=None, splitter='best')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.77      0.78     22509\n",
      "          1       0.41      0.42      0.41      8218\n",
      "\n",
      "avg / total       0.68      0.68      0.68     30727\n",
      "\n",
      "[[17420  5089]\n",
      " [ 4746  3472]]\n",
      "ROC-AUC  : 0.598\n",
      "Accuracy : 0.680\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "tree_model=DecisionTreeClassifier() \n",
    "tree_predicted,tree_predicted_probs, clf_ = build_model(data_train, target_train, data_test, target_test,  tree_model)\n",
    "# clf_.predict_proba(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_neighbors=5, p=2, weights='uniform')\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.87      0.80     22509\n",
      "          1       0.29      0.15      0.20      8218\n",
      "\n",
      "avg / total       0.62      0.67      0.64     30727\n",
      "\n",
      "[[19500  3009]\n",
      " [ 6987  1231]]\n",
      "ROC-AUC  : 0.508\n",
      "Accuracy : 0.675\n"
     ]
    }
   ],
   "source": [
    "# K Neighbors Classifier\n",
    "knn_model=KNeighborsClassifier()\n",
    "knn_predicted,knn_predicted_probs, clf_ =  build_model(data_train, target_train, data_test, target_test, knn_model)\n",
    "# clf_.predict_proba(test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84     22509\n",
      "          1       0.55      0.36      0.43      8218\n",
      "\n",
      "avg / total       0.73      0.75      0.73     30727\n",
      "\n",
      "[[20104  2405]\n",
      " [ 5277  2941]]\n",
      "ROC-AUC  : 0.626\n",
      "Accuracy : 0.750\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Classifier\n",
    "gbrt_model=GradientBoostingClassifier() \n",
    "gradient_predicted,gradient_predicted_probs, clf_=  build_model(data_train, target_train, data_test, target_test,  gbrt_model)\n",
    "# clf_.predict_proba(test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr',\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.91      0.83     22509\n",
      "          1       0.51      0.26      0.34      8218\n",
      "\n",
      "avg / total       0.70      0.74      0.70     30727\n",
      "\n",
      "[[20457  2052]\n",
      " [ 6090  2128]]\n",
      "ROC-AUC  : 0.584\n",
      "Accuracy : 0.735\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regresssion Classifier\n",
    "logit_model=LogisticRegression() \n",
    "logit_predicted,logit_predicted_probs, clf_=  build_model(data_train, target_train, data_test, target_test,logit_model)\n",
    "# clf_.predict_proba(test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold_rebalancer(dt):\n",
    "    if dt > 0.495:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "## testing different class thresholds\n",
    "prob_check = pd.DataFrame(ada_predicted_probs) \n",
    "prob_check['target_test'] =  target_test\n",
    "prob_check['ada_predicted'] =  ada_predicted\n",
    "\n",
    "prob_check.columns = ['neg','pos','target_test','ada_predicted']\n",
    "x = prob_check[prob_check.target_test == 1]\n",
    "# x[x.ada_predicted == 0]\n",
    "\n",
    "\n",
    "prob_check['rebalance'] = prob_check.pos.apply(threshold_rebalancer)\n",
    "\n",
    "\n",
    "prob_check.head()\n",
    "\n",
    "print metrics.confusion_matrix(prob_check.target_test,prob_check.rebalance)\n",
    "print 'ROC-AUC  : %0.3f' %(metrics.roc_auc_score (prob_check.target_test,prob_check.rebalance))\n",
    "print 'Accuracy : %0.3f' %(metrics.accuracy_score (prob_check.target_test,prob_check.rebalance))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 89960, 1: 32947})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are using the cross validated models to make predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building rf_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n",
      "Building ada_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n",
      "Building logit_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n",
      "Building knn_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n",
      "Building gbrt_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n",
      "Building tree_model\n",
      "sklearn.cross_validation.StratifiedKFold(labels=[0 1 0 ..., 0 0 0], n_folds=5, shuffle=True, random_state=23)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# target = np.array(target_train)\n",
    "# train = np.array(data_train)\n",
    "\n",
    "\n",
    "# target = np.array(shuffle_target)\n",
    "# train = np.array(shuffle_data)\n",
    "\n",
    "target = target\n",
    "train =  np.array(train_data)\n",
    "test =  np.array(test_data)\n",
    "\n",
    "\n",
    "test_data_results = {}\n",
    "# Iterate throught the models\n",
    "clfs = ['rf_model', 'ada_model', 'logit_model', 'knn_model', 'gbrt_model','tree_model']\n",
    "for clf in clfs:\n",
    "    print 'Building', clf\n",
    "    # K-Fold cross validation. 10 folds.\n",
    "    cv = StratifiedKFold(target, n_folds=5, indices=None, shuffle=True, random_state=23)\n",
    "    print cv\n",
    "\n",
    "    #iterate through the training and test cross validation segments, run the classifier on each one and aggregating the resultss\n",
    "    results = []\n",
    "\n",
    "    for traincv_indx, testcv_indx in cv:\n",
    "        model_probas = eval(clf).fit(train[traincv_indx], target[traincv_indx])\n",
    "        results.append(model_probas.predict_proba(test))\n",
    "    \n",
    "    # store the probabilities for each cross validated model\n",
    "    probs = model_ensemble(*results, mode = 'probs')\n",
    "    test_data_results[clf] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate probabilities ofr belonging to either class by combining the results of the diffrent models.\n",
    "predictions = pd.DataFrame(model_ensemble(*test_data_results.values(), mode = 'probs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob_No_Purchase</th>\n",
       "      <th>Prob_Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0.855428</td>\n",
       "      <td> 0.144572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 0.790917</td>\n",
       "      <td> 0.209083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 0.709249</td>\n",
       "      <td> 0.290751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 0.519834</td>\n",
       "      <td> 0.480166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 0.762681</td>\n",
       "      <td> 0.237319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 0.800037</td>\n",
       "      <td> 0.199963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 0.804325</td>\n",
       "      <td> 0.195675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 0.787923</td>\n",
       "      <td> 0.212077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 0.904841</td>\n",
       "      <td> 0.095159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 0.609814</td>\n",
       "      <td> 0.390186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prob_No_Purchase  Prob_Purchase\n",
       "0          0.855428       0.144572\n",
       "1          0.790917       0.209083\n",
       "2          0.709249       0.290751\n",
       "3          0.519834       0.480166\n",
       "4          0.762681       0.237319\n",
       "5          0.800037       0.199963\n",
       "6          0.804325       0.195675\n",
       "7          0.787923       0.212077\n",
       "8          0.904841       0.095159\n",
       "9          0.609814       0.390186"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.columns= ['Prob_No_Purchase','Prob_Purchase']\n",
    "predictions.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_bool = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_predictions(dt):\n",
    "    '''\n",
    "    Get Predictions using a threshold of 0.5\n",
    "    '''\n",
    "    if dt > 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "predictions_bool['predictions'] = predictions['Prob_Purchase'].apply(get_predictions)\n",
    "predictions_bool.to_csv('predictions_bool.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Improvements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are probably a few more things we could to improve our model. Some of them include \n",
    "- Rebalancing the classes in the training data by upsampling the minority class via bootstraping \n",
    "- Since one class is severly under-represented, we can assign higher importance weights to that class.\n",
    "- We could probably always add on more enhanced features to our feature vectors to enable us extract more signals for each of the classes\n",
    "- We could build feature from the frequent item set miniing of the activities\n",
    "- We couldalso explore sequence mining to see if certain sequences give us more distinct signatures for each class\n",
    "- We could also use support / confidence scores from doing associative mining on the activities\n",
    "- Hyper-parameter tuning\n",
    "\n",
    "Doing the things above might enable our training algorithm to essentially see more instances / examples of the minority class and hence it will be able to extract those signals better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
